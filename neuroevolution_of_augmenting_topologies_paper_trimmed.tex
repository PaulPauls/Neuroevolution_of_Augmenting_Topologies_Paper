% ######################################################################################################################

\documentclass[journal, a4paper]{IEEEtran}

\usepackage{graphicx}       % For graphics, photos, etc
\usepackage{hyperref}       % For URL and href
\usepackage{amsmath}        % For advanced mathematical formatting and symbols
\usepackage{blindtext}      % For placeholder text
\usepackage{listings}       % For code listings
\usepackage{color}          % For color
\usepackage{background}     % For draft watermark
\usepackage{datetime}       % For precisde dating in watermark

\graphicspath{{./illustrations/}}

\definecolor{green}{rgb}{0, 0.66, 0}
\definecolor{red}{rgb}{1, 0, 0}
\definecolor{gray}{rgb}{0.5, 0.5, 0.5}
\definecolor{orange}{rgb}{1, 0.66, 0}
\definecolor{codebg}{rgb}{0.97, 0.97, 0.97}

\lstdefinestyle{c-style}{
  language={[ANSI]C},
  frame=single,
  backgroundcolor=\color{codebg},
  commentstyle=\itshape\color{green},
  keywordstyle=\color{blue},
  numberstyle=\tiny\color{gray},
  stringstyle=\color{orange},
  basicstyle=\fontsize{7}{7}\ttfamily,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2
}

% ######################################################################################################################

\begin{document}

\title{An Introduction of Neuroevolution of Augmenting Topologies from the Ground Up}
\author{Paul Pauls, \textit{Technical University of Munich (TUM)}\\
        Advisor: Michael Adam, \textit{Technical University of Munich (TUM)}}
\markboth{Neuroevolution of Augmenting Topologies}{}
\maketitle

% Place small Watermark indicating that this is currently a draft on the left side
\backgroundsetup{
    position=current page.west,
    angle=90,
    nodeanchor=west,
    vshift=-2mm,
    hshift=-25mm,
    opacity=1,
    scale=3,
    color=gray,
    contents=DRAFT from \today
}

%\SetWatermarkText{DRAFT}
%\SetWatermarkScale{0.5}

% While Paper is in development shall I include this table of contents as a quick overview
% \tableofcontents

\begin{abstract}
    Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, especially in times of deep learning with countless parameters to configure. This paper shows one way to automatically create those deep learning topologies by introducing the system 'Neuroevolution of Augmenting Topologies' from the ground up. First the term neuroevolution is determined and established, whereupon the key aspects that define NEAT are illustrated, closing with an outlook of advancements building upon NEAT.
\end{abstract}



% ######################################################################################################################

\section{Introduction}

\IEEEPARstart{W}{ith} the rise of Deep Learning in this decade, see especially \cite{kri12, cir12, sch14}, did the machine learning research community increasingly face the challenge of having to configure even more hyperparameters, create even more layers and run even more tests. In order to ease this design process did the concept of \textit{Automated Machine Learning} (short form: AutoML) come into focus. One aspect of AutoML - the evolution of artificial neural networks (short form: ANNs) - is addressed in this paper and its most prominent representative - NEAT - is thoroughly discussed. 

This evolution of artificial neural networks is called \textit{neuroevolution} and it is a form of evolutionary algorithm that generates specific ANNs through modification of its parameters, topology and rules in order to maximize the ANN's accuracy or fitness score. The neuroevolution algorithm seeks to modify the ANN in an evolutionary process similar to the Darwinian process that produced human brains and its process-summarizing maxim 'survival of the fittest'. First methods using neuroevolution can be traced back to the 1980s and 1990s \cite{fro18}, while the first evolutionary algorithms were conceived in the 1950s by Alan Turing and Nils Barricelli \cite{tur50}.



% ######################################################################################################################

\section{Neuroevolution and Evolutionary Algorithms}

To better characterize neuroevolution in this chapter is it best to first roughly categorize it, whereupon the following sections describe the categories in detail. A \textit{neuroevolution algorithm} is a \textit{genetic algorithm}, whose search-space (or genotypes) consist only of artificial neural networks. A \textit{genetic algorithm} in turn is a \textit{evolutionary algorithm} that evolves genotypes - genetically encoded representations of the actual solution (phenotype) - through mutation, recombination and selection.



\subsection{Evolutionary and Genetic Algorithms}

An evolutionary algorithm (short form: EA) is defined as "a generic population-based and meta-heuristically optimized algorithmic solution to an applied problem" \cite{hol12}. When breaking this complex definition down into simpler terms, is the first thing that should be clarified about EAs the fact that they are no algorithmic solution to the applied problem in and of themselves. Rather can be said about EAs that they are meta-algorithms that create another optimized algorithm, which then solves the applied problem. An evolutionary algorithm therefore encodes a method of how to come up with the best solution to an algorithmic problem.

Evolutionary algorithms set out to finding this best algorithmic solution through a \textit{population-based} method. This means that EAs manage an arbitrary variety of algorithmic solutions - all of which differ and solve the applied problem with various grades of accuracy or fitness scoring. Each of these algorithmic solutions is called a \textit{member} of the evolutionary algorithms' population. To determine the best member of the population does the evolutionary algorithm assign each a \textit{fitness score} after it is created. In the context of neuroevolution for example is this fitness score calculated by judging the accuracy of the artificial neural network.

However, the question remains how the members of the population are created in a sensible way so that they may represent a reasonable algorithmic solution to the problem and eventually an optimized one. This is the point at which the EAs' aspect of \textit{meta-heuristic optimization} comes into play. Each new member in a population is conceived by recombining and/or mutating a single or multiple existing members of the population. Presuming that the existing members, which are recombined to create the new member, are chosen to be the high fitness scoring members, does the process constitute an optimization procedure resembling Darwinian evolution. Evolutionary algorithms therefore breed a single increasingly optimized algorithmic solution through evolutionary intercombination of already existing algorithmic solutions - hence representing the mentioned optimization process. 

The possible methods of intercombination between existing members - such as mutation, recombination and selection - are all inspired by biological evolution.  For the sake of brevity will only the subsequent chapter \ref{ch:neuroevolution} explain those intercombination methods in detail and how they apply to neuroevolution algorithms. The mentioned optimization process achieved through these intercombination methods is considered \textit{meta-heuristic} because the optimization process is possible with incomplete information or limited computational capacity. Thus even when the feedback - the mentioned (possibly incomplete) information through which the EA is able to determine a sensible fitness score - of the applied problem is limited or sparse, is a fruitful traversal through the search-space still possible (e.g. via a lucky mutation).

At last can be said that the evolutionary algorithms population-based methodology is considered \textit{generic} because it does not dictate how the members of the population are encoded. Though an evolutionary algorithm needs to eventually return an algorithmic solution to the applied problem, does it not dictate that the members need to be algorithms themselves. This is were genetic algorithms come into play.

Genetic algorithms (short form: GAs) are evolutionary algorithms whose members are not algorithms per se, but genetic-like encodings which are eventually translated into algorithms by a user-specified component of the genetic algorithm. The gene-like encoded member in a GA is called its \textit{genotype}, whereas its corresponding translated algorithm is called its \textit{phenotype}.

The defining advantage of representing members as a gene-like encodings instead of an algorithm in memory is that intercombination methods like mutation and recombination - central aspects of evolutionary algorithms - are vastly easier and faster on relatively simple genetic encodings than on complex specified algorithms. Figure \ref{ill:binary_encoding} illustrates a binary encoding of an ANN and showcases well how such a complex algorithm as an artificial neural network is significantly simpler represented as a genetic encoding and how such a genetic encoding can be vastly easier recombined than the algorithm itself.



\subsection{Neuroevolution}\label{ch:neuroevolution}

A proper - from the ground up - definition of neuroevolution is now possible. Neuroevolution is the - possibly boundless - process in which by the means of a genetic algorithm its population of artificial neural networks is increasingly optimized in order to maximize the accuracy or fitness of the best ANN. Neuroevolution does so by continuously improving the members of its population through intercombination methods like mutation, recombination and selection.

\begin{figure}
    \includegraphics[width=0.45\textwidth]{{Binary_ANN_Encoding_-_yao99}}
    \caption{Illustration of a binary encoding of an ANN. (Source: \cite{yao99})}
    \label{ill:binary_encoding}
\end{figure}

The intercombinatory method of \textit{mutation} in the context of neuroevolution means that the genotype of a chosen member is in some way modified by adding to, changing or removing from the genotype representation. The manner and probability in which this modification takes place is completely up to the implementation specifics of the respective neuroevolution algorithm. To give an example mutation for an ANN, is it possible to imagine a binary encoded genotype as seen in figure \ref{ill:binary_encoding}, which then has some bits flipped, added or removed, possibly resulting in a new node or connection in its corresponding phenotype.

The intercombinatory method of \textit{recombination} in the context of Neuroevolution means that the genotype of two or more arbitrary (though most often high performing) members are combined, forming a new member. This is done in the hopes that those parts of the genotype that encode member-distinct features combine into the newly created genotype and encode an ANN that performs even better than both \textit{parent}-members in isolation. An example of such a recombination, though an impaired one as the figure actually represents the flawed process of the 'Competing Conventions Problem', can be seen in figure \ref{ill:comp_conv}. In this example cross two simplified genotypes consisting of three possible genes over, whereas each possible gene in the resulting child takes over a gene of the same position from either parent. Again is the manner and probability in which this modification is performed completely up to the implementation specifics of the respective neuroevolution algorithm.

Last to address is the intercombinatory method of \textit{selection}. As previously defined does the process of neuroevolution work on populations; these however are often of fixed size in most neuroevolution algorithms. The purpose of this restriction is to force the neuroevolution process to remove low performing members from the population from which possible parents for intercombination are chosen, by only allowing a limited number of members to exist. Once all members of the population have been assigned a fitness score, is this current state of the population considered a specific \textit{generation}. The method of \textit{selection} then removes certain members (usually the low performing) from the population after each generation. The intercombinatory methods of mutation and recombination subsequently add new members to the population and the whole population is evaluated again, marking the start of the next generation. The method of selection is also applicable in the case of an unrestricted population size, e.g. by removing members that score too far below the current best member.

All those Details of the neuroevolution process, e.g. how the encoding scheme specifies genotypes and their translation into the phenotype ANNs, how the initial population is created, which members are chosen as parents for intercombinatory methods or simply how exactly the intercombinatory methods are performed are all left to the specifics of the neuroevolution algorithm.



% ######################################################################################################################

\section{NeuroEvolution of Augmenting Topologies (NEAT)} \label{sec:neat}

Kenneth O.Stanley and Risto Miikkulainen co-published an approach to neuroevolution in the year 2002, which they called \textit{Neuroevolution of Augmenting Topologies} - or in short \textit{'NEAT'} - in their paper "Evolving Neural Networks through Augmenting Topologies" \cite{sta02_1}. At the time of envisionment was NEAT considered one of the most promising approaches to ANN evolution and it is still considered a viable approach and a benchmark algorithm in neuroevolution to this day. The first section in this chapter will outline what aspects of NEAT set it apart from the preceding research and enabled its leap in performance, which will be looked upon in the second section. This chapter closes with a short overview of great implementations and projects that realize or are realized with NEAT.



\subsection{Key Aspects of NEAT and Differences to Preceding Neuroevolution}

In his dissertation, titled 'Efficient Evolution of Neural Networks through Complexification' \cite{sta04} and published in 2004, did Stanley present three main technical challenges to the current state of neuroevolution and evolving structure incrementally. He asked the following three questions that summarize these challenges \cite[page 4]{sta04}:

\begin{itemize}
    \item "Is there a genetic representation that allows disparate topologies to cross over in a meaningful way?"
    \item "How can topological innovation that needs a few generations to be optimized be protected so that it does not disappear from the population prematurely?"
    \item "How can topologies be minimized throughout evolution without a contrived fitness function that measures complexity explicitly?"
\end{itemize}

Stanley answered these questions with the following key aspects of NEAT, which differentiate it from the preceding neuroevolution algorithms and resulted in a powerful evolutionary method that can solve benchmark problems faster than previous methods and also makes entirely new applications possible.



\subsubsection{\textbf{Historical Markings}}

Historical markings were introduced to overcome the challenge of \textit{Competing Conventions} - visualized in figure \ref{ill:comp_conv}. This example illustrates the attempt to cross over [A,B,C] and [C,B,A], which can result in [C,B,C], a representation that has lost one third of the information that both of the parents had. The probability of such severe genetic damage when looking at nontrivial crossovers (where an offspring is not simply a duplicate of a parent) with no protection against this sort of information erasure lies at 66.6\% - as extensively calculated by Stanley in \cite[page 19]{sta04}.

\begin{figure}
    \includegraphics[width=0.45\textwidth]{{Competing_Conventions_Crossover_-_sta02_2}}
    \caption{Illustration of the \textit{Competing Conventions} problem. (Source: \cite{sta02_2})}
    \label{ill:comp_conv}
\end{figure}

The approach of historical markings offers a solution to this grave problem by introducing a global innovation number. Whenever a new gene appears through structural mutation (which in the context of NEATs' direct encoding effectively means whenever a new node or connection appears), a global innovation number is incremented and assigned to that gene. This allows to track the historical origin of each gene and consequently which genes match up between all members of the population.

Keeping track of those genes allows to identify genes that represent the same structure (though possibly with different weights) and eventually allows to solve the Competing Conventions problem. The principle of historical markings does so by first of all, not allowing the same gene (with the same innovation number and therefore representing the same structure) to be present multiple times in the genotype. Secondly does the principle also prevent genes from erasing one another when crossing over when it is apparent that both genes have different innovation numbers and an erasure of either gene would be an erasure of information. Instead, due to the dynamic-length encoding employed by NEAT, is the genotype simply elongated and both genes (and therefore both represented structures) are placed next to each other in the genotype. Though this on the other hand does not mean the genotype itself only ever increases in size. Genes in the genotype can be removed and the genotype can subsequently shrink, though this is not done in the crossover process but rather during the intercombinatory method of mutation, which can \textit{disable} and therefore remove individual genes. 

This elaboration of the principle of historical markings explains how the crossover in figure \ref{ill:comp_conv} would take place without severe genetic damage. Then again does figure \ref{ill:ann_recomb_innov_num} illustrate such a functional, meaning information preserving, recombination process with the explicit usage of innovation numbers.

\begin{figure}
    \includegraphics[width=0.45\textwidth]{{ANN_Recombination_With_Innovation_Numbers_-_sta04}}
    \caption{ANN crossover in NEAT using \textit{Innovation Numbers}. (Source: \cite{sta04})}
    \label{ill:ann_recomb_innov_num}
\end{figure}



\subsubsection{\textbf{Speciation}}
Speciation, also known as \textit{niching}, has been studied in GAs but has rarely been applied to NE prior to its introduction in NEAT \cite[page 25]{sta04}; Even though speciation is a crucial part of NEAT and as Stanley verified in an ablation study does the lack of speciation significantly limit NEATs' ability to add and maintain new topologies \cite{sta02_2} \cite[chap 4.3]{sta04}. 

The underlying problem and reason for the necessity of speciation is that topological innovation - e.g. a drastically interrupting node or connection - often underperforms compared to the other more matured members of the population. Though this topological innovation may simply need time to optimize its weights or set up the new member for another mutation that in turn enables a significant performance boost. Speciation therefore protects innovation following the philosophy that new ideas must be given time to reach their potential before they are eliminated. In the context of neuroevolution does this mean that innovative members must be given time to optimize their weights or further mutate favorably before they are eliminated.

The principle of speciation protects innovation by using explicit fitness sharing, a method under which individuals that are sharing a niche are forced to also share the fitness score of all members in the niche. This effectively means that each members fitness is postadjusted according to the following equation \cite[chap 3.3]{sta04}: 

If $f_i$ is i's fitness before sharing, then after sharing it becomes $f'_i$ according to

\begin{align}
    f'_i &= \frac{f_i}{\sum_{j=1}^{n} sh(\delta(i,j))}
\end{align}

This explicit fitness sharing therefore effectively means that new species don't have to compete with the best members, but only the best niches, which again are put into perspective through the lower performing members in the niche whose weights are likely not set optimally. This favors small and most often new niches since weight optimization isn't a factor anymore and therefore keeps diversity in niches and hence topological innovation high. An important point to make though is that this principle of speciation obviously requires a distance metric between genotypes in order to determine if two members are sufficiently different to place them in distinct species. NEAT provides such a distance metric through the principle of historical markings.



\subsubsection{\textbf{Complexification}}
The principle of complexification is the simplest principle and addresses a problem Stanley identified in most preceding neuroevolution algorithms. Many preceding neuroevolution algorithms would start out with an often considerably large and randomly mutated initial population with the intention to provide genetic diversity in the gene pool. The intention was that this diversity would provide the means to thoroughly and quickly traverse through the search space by mutation, as many genetic features were already present in the initial population. Most often did these algorithms also include a functional unit of the algorithm that was only intended to minimize the ANN through degenerative mutation. This was required as the necessity of topological innovation - its initially randomly mutated population - usually left significant clutter in the form of unnecessary genes and genetic features.

This necessity of a randomly mutated initial population to produce innovation however isn't a necessity in NEAT, as the principle of speciation protects innovation and the principle of historical markings allows for lossless and clean recombination between members. The principle of complexification therefore states to provide a minimal initial population, which is only expanded upon. Because new genes (or topological features) only appear and endure if they represent a beneficial new structure, does this also eliminate the resource-costly requirement of a functional unit responsible for minimization.



\subsection{Performance of NEAT} \label{sec:neat_performance}

Stanley \& Miikkulainen also included thorough performance analysis in their papers introducing NEAT in 2002 and 2004 \cite{sta02_1, sta02_2, sta04}. Their analysis showed NEAT significantly outperforming most preceding NE methods in terms of speed and required evaluations in key benchmarks like the double pole balancing task \cite{and89} and the XOR topology building task.

The simpler of the two benchmarks - the XOR topology building task - is a sanity check for TWEANN algorithms. Because XOR is not linearly separable does a neural network require hidden units to solve it and therefore makes this benchmark suitable for testing NEATs' ability to evolve structure. It is clear that NEAT solves the XOR problem without trouble and in doing so keeps the topology small \cite[chap 4.1]{sta04}. 

\begin{figure}
    \includegraphics[width=0.45\textwidth]{{Table_Comparison_DPNV_Benchmark_-_sta02_2}}
    \caption{Performance Comparison for 'Double pole balancing without velocity information' task between CE, ESP and NEAT. (Source: \cite{sta02_2})}
    \label{ill:table_dpnv_benchmark}
\end{figure}

However, the double pole balancing task is of more importance, as this benchmark is well suited for performance comparison. This benchmark has been used in reinforcement learning and neuroevolution research for over 30 years \cite[chap 3.A]{sta02_2} and consists of two poles connected to a moving cart by a hinge, whereas the neural network must apply force to the cart to keep the poles balanced for as long as possible. Figure \ref{ill:table_dpnv_benchmark} lists the table showing the results of the 'double pole balancing without velocity information' experiment, in which NEAT is by far the fastest system on this challenging task, clearly even outperforming ESP (Enforced SubPopulations by Gomez \& Miikkulainen \cite{gom99}). This is relevant as ESP, unlike all other NE systems at the time, performs at least in the other 'double pole balancing with velocity information' experiment at the same level as NEAT \cite[chap 4.3.2]{sta02_1}. This underlines NEATs' ability to perform especially well in feedback-sparse environments.



% ######################################################################################################################

\subsection{Practical Applications of NEAT}

Practical applications of the NEAT system are plentiful as it is still relevant due to its high performance. One very prominent example of a great application of NEAT is the most accurate measurement to date of the mass of the top quark, which was computed by a very large team at the Tevatron collider in 2009 \cite{aal09}. Though NEAT was not only applied in physics, but also enabled pioneering work in advancing video game playing AI or medical AI. 
The work \cite{hau12} of a single researcher - Matthew Hausknecht - on Atari video game playing utilizing HyperNEAT (a very promising Advancement of NEAT introduced in 2009) was so pioneering that it was later referenced by the DeepMind Team \cite{Mni13}, who eventually created the famous AlphaStar AI. NEAT was also applied in a recent study published in 2018, which compared the achieved accuracy of different neuroevolution approaches in the context of detecting tumors in medical images \cite{fra18}. NEATs' performance was similar to the established algorithms, even when executing a much smaller number of generation.
    
Each of these applications implemented their own version of NEAT, as - unlike for classical machine learning - there exists no well established framework for neuroevolution. The official NEAT software catalog \cite{neat_software19} lists 25 different implementations and libraries for vanilla NEAT alone, the most prominent one probably being NEAT-Python \cite{cod19} by CodeReclaimers. Training an agent to play SuperMario World by utilizing this NEAT-Python library can be realized in under 100 lines of code with good results \cite{pau19_smw}.

There are also currently efforts being made \cite{pau19_tefne} to implement NEAT in the upcoming Tensorflow 2.0 \cite{tf_beta19} release as an add-on \cite{tf_addons19} library utilizing Tensorflows newly introduced dynamic computational graphs.



% ######################################################################################################################

\section{Conclusion}

As this paper outlines - and the past decade proves - is neuroevolution a promising approach to developing topologies and weights of artificial neural networks. NEAT was a significant advancement for the field of neuroevolution at the time it was introduced in the year 2002 and is still to this day an important benchmark. Even so did the research community of neuroevolution not stop innovating and created groundbreaking new neuroevolution algorithms - some being advancements of the original NEAT. Stanley, Risi, D'Ambrosio and Lehman introduced HyperNEAT \cite{sta09} and its refinement ES-HyperNEAT \cite{ris11} in 2009/2011, further enhancing it with new fitness function objectives like \textit{Novelty Search} \cite{leh11} in 2011. Furthermore did Miikkulainen \& Liang bring the innovations of Deep Learning to neuroevolution introducing CoDeepNEAT \cite{mii17} in 2017, while Real \& Aggarwal were even able to design a neuroevolution system that surpasses hand-designs for the first time in 2018 \cite{rea19}.

Creating established neuroevolution frameworks that will efficiently use computational resources like the GPU will likely further this field of research even more, as the traditional machine learning frameworks already demonstrated.



% ######################################################################################################################

\begin{thebibliography}{5}

  \bibitem{tur50}
    Turing - Computing Machinery and Intelligence; Oct. 1950;
    \url{https://academic.oup.com/mind/article/LIX/236/433/986238}

  \bibitem{and89}
    Anderson - Learning to control an inverted pendulum using neural networks; 1989;
    \url{https://ieeexplore.ieee.org/document/24809}

  \bibitem{yao99}
    Yao - Evolving Artificial Neural Networks; 1999;
    \url{http://avellano.fis.usal.es/~lalonso/compt_soft/articulos/yao99evolving.pdf}

  \bibitem{gom99}
    Gomez, Miikkulainen - Solving Non-Markovian Control Tasks with Neuroevolution; 1999;
    \url{http://nn.cs.utexas.edu/downloads/papers/gomez.ijcai99.pdf}

  \bibitem{sta02_1}
    Stanley, Miikkulainen - Evolving Neural Networks through Augmented Topologies; 2002;
    \url{http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf}

  \bibitem{sta02_2}
    Stanley, Miikkulainen - Efficient Evolution of Neural Network Topologies; 2002;
    \url{http://nn.cs.utexas.edu/downloads/papers/stanley.cec02.pdf}

  \bibitem{sta04}
    Stanley - Efficient Evolution of Neural Networks through Complexification; Aug 2004;
    \url{http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf}

  \bibitem{sta09}
    Stanley, Dâ€™Ambrosio, et al - A Hypercube-Based Indirect Encoding for Evolving Large-Scale Neural Networks; 2009;
    \url{http://axon.cs.byu.edu/~dan/778/papers/NeuroEvolution/stanley3**.pdf}

  \bibitem{aal09}
    Aaltonen, Adelman, et al - Measurement of the top-quark mass with dilepton events selected using neuroevolution at CDF; Apr 2009;
    \url{https://www.ncbi.nlm.nih.gov/pubmed/19518620}

  \bibitem{ris11}
    Risi, Stanley - Enhancing ES-HyperNEAT to Evolve More Complex Regular Neural Networks; Jul 2011;
    \url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.365.4332}

  \bibitem{leh11}
    Lehman, Stanley - Novelty Search and the Problem with Objectives; Oct 2011;
    \url{https://www.cs.ucf.edu/eplex/papers/lehman_gptp11.pdf}

  \bibitem{hau12}
    Hausknecht - A Neuroevolution Approach to General Atari Game Playing; 2012;
    \url{https://www.cs.utexas.edu/~mhauskn/projects/atari/movies.html}

  \bibitem{cir12}
    Ciresan, Giusti, et al - Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images; 2012;
    \url{http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf}

  \bibitem{kri12}
    Krizhevsky, Sutskever, et al - ImageNet Classification with Deep Convolutional Neural Networks; 2012;
    \url{https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}

  \bibitem{hol12}
    Holland - Scholarpedia Article on 'Genetic Algorithms'; Oct 2012;
    \url{http://www.scholarpedia.org/article/Genetic_algorithms}

  \bibitem{Mni13}
    Mnih, Kavukcuoglu, et al - Playing Atari with Deep Reinforcement Learning; Dec 2013;
    \url{https://arxiv.org/abs/1312.5602}

  \bibitem{sch14}
    Schmidhuber - Deep Learning in Neural Networks; Apr 2014;
    \url{https://arxiv.org/abs/1404.7828}

  \bibitem{mii17}
    Miikkulainen, Liang, et al - Evolving Deep Neural Networks; Mar 2017;
    \url{https://arxiv.org/abs/1703.00548}

  \bibitem{fra18}
    Franca - Neuroevolution of Augmenting Topologies Applied to the Detection of Cancer in Medical Images; Feb 2018;
    \url{http://www.bcc.ufrpe.br/sites/www.bcc.ufrpe.br/files/Luiz%20Fran%C3%A7a.pdf}

  \bibitem{fro18}
    Frolov - Neuroevolution: A Primer on Evolving Artificial Neural Networks; Oct 2018;
    \url{https://www.inovex.de/blog/neuroevolution/}

  \bibitem{rea19}
    Real, Aggarwal, et al - Regularized Evolution for Image Classifier Architecture Search; Feb 2019;
    \url{https://arxiv.org/abs/1802.01548}

  \bibitem{cod19}
    CodeReclaimers - NEAT Python; Jun 2019;
    \url{https://github.com/codereclaimers/neat-python}

  \bibitem{neat_software19}
    NEAT Software Catalog; Jun 2019;
    \url{http://eplex.cs.ucf.edu/neat_software/}

  \bibitem{pau19_smw}
    Paul Pauls - SuperMario World NEAT Agent; Jun 2019;
    \url{https://github.com/PaulPauls/SuperMarioWorld-NEAT-Agent}

  \bibitem{tf_beta19}
    Tensorflow 2.0 Beta; Jun 2019;
    \url{https://www.tensorflow.org/beta}

  \bibitem{tf_addons19}
    Tensorflow addons; Jun 2019;
    \url{https://github.com/tensorflow/addons}

  \bibitem{pau19_tefne}
    Paul Pauls - Tensorflow Neuroevolution; Jun 2019;
    \url{https://github.com/PaulPauls/Tensorflow-Neuroevolution}

\end{thebibliography}

\end{document}
